{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bbcf1c-b302-44ba-aee5-c36f08782bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:339712893183:pipeline/ChurnPredictorPipeline/execution/jubmpx3lqdn0', sagemaker_session=<sagemaker.workflow.pipeline_context.PipelineSession object at 0x7facf4c4cd00>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TuningStep, TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, CreateModelStep, TransformStep\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "\n",
    "# SageMaker session setup\n",
    "role = 'arn:aws:iam::339712893183:role/SagemakerNotebookRole'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "# Define the S3 bucket and prefix\n",
    "bucket = 's3-churn-predictor'\n",
    "prefix = 'output'\n",
    "\n",
    "# Preprocessing step\n",
    "preprocessing_script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(framework='sklearn', region=sagemaker_session.boto_region_name, version='0.23-1'),\n",
    "    command=['python3'],\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name='PreprocessingStep',\n",
    "    processor=preprocessing_script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source='s3://s3-churn-predictor/data/data.csv', destination='/opt/ml/processing/input')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source='/opt/ml/processing/train', destination=f's3://{bucket}/data/train'),\n",
    "        ProcessingOutput(output_name=\"test\", source='/opt/ml/processing/test', destination=f's3://{bucket}/data/test')\n",
    "    ],\n",
    "    code='scripts/preprocessing.py'\n",
    ")\n",
    "model_path = f\"s3://{bucket}/output\"\n",
    "\n",
    "pytorch_estimator = PyTorch(\n",
    "    entry_point='train.py',  # Update to your actual script name\n",
    "    source_dir='scripts',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        'bucket-name': bucket  # Using the bucket name\n",
    "    },\n",
    "    output_path=model_path  # Set the output path for the model artifacts\n",
    ")\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'lr': ContinuousParameter(0.0001, 0.1),\n",
    "    'batch-size': IntegerParameter(32, 128)\n",
    "}\n",
    "\n",
    "# Create a HyperparameterTuner object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=pytorch_estimator,\n",
    "    objective_metric_name='validation:auc',\n",
    "    objective_type='Maximize',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'validation:auc', 'Regex': 'Validation AUC: ([0-9\\\\.]+)'}\n",
    "    ],\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=4\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define the tuning step using the tuner\n",
    "tuning_step = TuningStep(\n",
    "    name='ChurnPredictorTuning',\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"test\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get the top model's S3 URI using tuning_step\n",
    "top_model_s3_uri = tuning_step.get_top_model_s3_uri(top_k=0, s3_bucket=bucket, prefix=prefix)\n",
    "\n",
    "\n",
    "# Define the EvaluationStep\n",
    "evaluation_script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(framework='sklearn', region=sagemaker_session.boto_region_name, version='0.23-1'),\n",
    "    command=['python3'],\n",
    "    instance_type='ml.m5.large',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ChurnEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluationStep',\n",
    "    processor=evaluation_script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=top_model_s3_uri, destination='/opt/ml/processing/models'),\n",
    "        ProcessingInput(source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri, destination='/opt/ml/processing/test')\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source='/opt/ml/processing/evaluation', destination=f's3://{bucket}/evaluation')\n",
    "    ],\n",
    "    code='scripts/evaluate.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# Define the Model object using the best model from TuningStep\n",
    "model = Model(\n",
    "    image_uri=pytorch_estimator.training_image_uri(),\n",
    "    model_data=top_model_s3_uri,  # Use the top model's S3 URI directly\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Define the CreateModelStep using the top model's S3 URI\n",
    "create_model_step = CreateModelStep(\n",
    "    name='CreateModelStep',\n",
    "    model=model,\n",
    "    inputs=sagemaker.inputs.CreateModelInput(instance_type='ml.m5.large')\n",
    ")\n",
    "\n",
    "# Define ModelMetrics for registration\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"s3://s3-churn-predictor/evaluation/evaluation.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define model_package_group_name\n",
    "model_package_group_name = \"ChurnModelPackageGroup\"\n",
    "\n",
    "# Define RegisterModelStep using estimator and model_data\n",
    "register_model_step = RegisterModel(\n",
    "    name=\"RegisterChurnModel\",\n",
    "    estimator=pytorch_estimator,\n",
    "    model_data=top_model_s3_uri,  # Assuming top_model_s3_uri is defined earlier\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define the ConditionStep\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckAUC\",\n",
    "    conditions=[\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=JsonGet(\n",
    "                step_name=evaluation_step.name,\n",
    "                property_file=evaluation_report,\n",
    "                json_path=\"classification_metrics.auc_score.value\"\n",
    "            ),\n",
    "            right=0.75\n",
    "        )\n",
    "    ],\n",
    "    if_steps=[create_model_step, register_model_step],\n",
    "    else_steps=[]\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    name='ChurnPredictorPipeline',\n",
    "    parameters=[],\n",
    "    steps=[preprocessing_step, tuning_step, evaluation_step, condition_step],\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Create and start the pipeline\n",
    "pipeline.create(role_arn=role)\n",
    "pipeline.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9c375-1c20-4198-915c-61a99084c999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
